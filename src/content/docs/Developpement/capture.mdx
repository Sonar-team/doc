---
title: Comment capturer des paquets rÃ©seau en Rust avec Tauri
description: Un guide de terrain, Ã©tape par Ã©tape, pour comprendre la construction d'une fonction de capture de paquets dans une application Tauri.
sidebar:
  order: 403
---

## Introduction

Pour comprendre comment capturer des paquets rÃ©seau en Rust dans une application **Tauri**, je vais te montrer **mon cheminement complet** â€” depuis lâ€™idÃ©e dâ€™un simple compteur jusquâ€™Ã  une sonde rÃ©seau robuste.

Ce nâ€™est pas juste un tutoriel. Câ€™est un **journal technique**, une sorte de carnet de bord dans lequel chaque problÃ¨me mâ€™a permis dâ€™apprendre quelque chose de nouveau : sur les threads, la gestion dâ€™Ã©tat, la communication UI/backend, ou les particularitÃ©s de la crate `pcap`.

---

## ğŸ›  Ã‰tape 1 â€“ DÃ©marrer avec un compteur dans un thread

Avant de capturer des paquets rÃ©seau, je veux **maÃ®triser le principe dâ€™un thread Rust contrÃ´lÃ© par Tauri**. Voici une fonction trÃ¨s simple qui **lance un thread de comptage** :

```rust
use tauri::command;
use std::time::Duration;
use std::thread;

/// Cette commande dÃ©marre un thread qui compte chaque seconde.
#[command(async)]
pub fn start_counter() {
    thread::spawn(move || {
        let mut count = 0;
        loop {
            count += 1;
            println!("Compteur: {}", count);
            thread::sleep(Duration::from_secs(1));
        }
    });

    println!("Thread de comptage lancÃ© !");
}
```

```mermaid
flowchart TD
    Start["start_counter() appelÃ©e"] --> ThreadStart["Spawn du thread"]
    ThreadStart --> Loop["Boucle infinie"]
    Loop --> Incr["IncrÃ©menter compteur"]
    Incr --> Print["Afficher avec println!"]
    Print --> Wait["Dormir 1 seconde"]
    Wait --> Loop
```


---

## ğŸ§© Ã‰tape 2 â€“ Ajouter le contrÃ´le `start` / `stop` du thread

### ğŸ§  Objectif
CrÃ©er un **compteur Rust contrÃ´lable** Ã  travers des **commandes Tauri** :
- âœ… DÃ©marrer le thread avec `start_counter`
- âœ… Lâ€™arrÃªter proprement avec `stop_counter`

---

### ğŸ“¦ Architecture du code

#### ğŸ§± Backend (Rust)

Tu introduis :
- une structure globale `AppState` partagÃ©e dans un `Arc<Mutex<...>>`
- un `CounterHandle` qui possÃ¨de un `stop_flag` partagÃ© entre thread et handler
- deux commandes Tauri :
  - `start_counter` qui vÃ©rifie quâ€™il nâ€™y a pas de thread dÃ©jÃ  actif
  - `stop_counter` qui signale au thread quâ€™il doit sâ€™arrÃªter

#### ğŸ’¡ Extrait clÃ©

```rust
pub fn stop(&self) {
    self.stop_flag.store(true, Ordering::Relaxed);
}
```

â¡ï¸ Cela coupe la boucle du thread dans `while !stop_flag.load(...)`.

---

### ğŸ”‚ Boucle de capture avec interruption

```rust
thread::spawn(move || {
    let mut count = 0;
    while !stop_flag.load(Ordering::Relaxed) {
        count += 1;
        println!("Compteur: {}", count);
        thread::sleep(Duration::from_secs(1));
    }
    println!("Thread terminÃ©.");
});
```

---

### ğŸ§  Pourquoi `Arc<AtomicBool>` ?
- **`Arc`** permet de **partager la donnÃ©e entre le thread et l'extÃ©rieur** (via le `CounterHandle`)
- **`AtomicBool`** Ã©vite les verrous pour un flag boolÃ©en simple
- `Ordering::Relaxed` est suffisant ici : pas besoin de synchronisation complexe

---

### ğŸ”— IntÃ©gration avec Tauri

#### Commande `start_counter`

```rust
if app.counter.is_some() {
    println!("DÃ©jÃ  en cours.");
    return;
}
```

â¡ï¸ Tu empÃªches le dÃ©marrage de plusieurs threads (bonne pratique).

#### Commande `stop_counter`

```rust
if let Some(counter) = app.counter.take() {
    counter.stop();
}
```

â¡ï¸ Tu "consommes" le compteur en le retirant de l'Ã©tat global (`take()`).

---

### ğŸ“Š Diagramme de sÃ©quence

```mermaid
flowchart TD
    UI["UI (Vue.js)"]
    start[/"start_counter"/]
    stop[/"stop_counter"/]
    checkFlag{{"stop_flag.load() == false ?"}}
    threadStart(["thread::spawn"])
    count[/"count += 1; sleep(1s)"/]
    endThread["Thread terminÃ©"]

    UI --> start
    start --> threadStart
    threadStart --> checkFlag
    subgraph     _____Loop
    checkFlag -- true --> count
    count --> checkFlag
    end
    checkFlag -- false --> endThread
    UI --> stop --> endThread

```

---

## ğŸ§  RÃ©sultat de cette Ã©tape

- âœ… Tu contrÃ´les **le lancement et lâ€™arrÃªt** du thread Ã  volontÃ©.
- âœ… Tu gÃ¨res **un seul thread actif Ã  la fois**.
- âœ… Tu poses les bases pour les Ã©tapes suivantes : `pause`, `resume`, puis `pcap`.

---

## ğŸ“ Ã‰tape 3 â€“ Ajout de `pause` et `resume` avec `Condvar`

### ğŸŒŸ Objectif
ContrÃ´ler l'Ã©tat d'exÃ©cution d'un thread via une **pause rÃ©versible**, sans tuer le thread, pour prÃ©parer les futurs cas d'usage comme la capture rÃ©seau avec interruption temporaire.

---

### ğŸ“„ Description technique

Tu introduis ici un **mÃ©canisme de pause/reprise** avec :

- Un `Arc<(Mutex<bool>, Condvar)>` appelÃ© `pause_flag`
- Le thread se met en attente (`Condvar::wait`) tant que `pause_flag == true`
- Une fonction `pause()` qui met `true`
- Une fonction `resume()` qui met `false` et `notify_all()`

---

### ğŸ› ï¸ Architecture de la boucle

```rust
while !stop_flag.load(Ordering::Relaxed) {
    let (lock, cvar) = &*pause_flag;
    let mut paused = lock.lock().unwrap();

    if *paused {
        println!("[DEBUG] Le thread est en pause, en attente...");
    }

    while *paused {
        paused = cvar.wait(paused).unwrap();
        println!("[DEBUG] Signal de reprise reÃ§u");
    }

    drop(paused);

    count += 1;
    println!("Compteur: {}", count);
    thread::sleep(Duration::from_secs(1));
}
```

---

### ğŸ”Š Fonctionnement en flowchart

```mermaid
flowchart TD
    Start["start() appelÃ©"] --> ThreadStart["spawn du thread"]
    ThreadStart --> Loop["Boucle: !stop_flag"]
    subgraph thread while
    Loop --> CheckPause{"pause_flag == true ?"}
    CheckPause -- Non --> Count["count += 1; sleep"]
    Count --> Loop
    end
    CheckPause -- Oui --> Wait["Condvar::wait"]
    Wait --> Resume["Reprise: notify_all"]
    Resume --> Loop
    Stop["stop() appelÃ©"] --> End["stop_flag = true"] --> Loop
```

---

### ğŸ”— Pourquoi `Condvar` ici ?

- Permet de bloquer le thread efficacement (**pas de spin/sleep inutile**)
- Attente conditionnelle, sans gaspiller de CPU
- Synchronisation typique dans les threads bloquants

---

### ğŸ“Š Bilan de l'Ã©tape

| Fonction | RÃ´le |
|----------|------|
| `start()` | Lance le thread si pas dÃ©jÃ  actif |
| `stop()` | Coupe la boucle et rÃ©veille s'il Ã©tait en pause |
| `pause()` | Met le thread en attente |
| `resume()` | RÃ©veille le thread bloquÃ© |

---

### ğŸ“‰ Limites observÃ©es

- Si on ne veut **pas bloquer** le thread (ex : avec `pcap` en mode `nonblock`), ce modÃ¨le est **trop complexe**
- Risques de **deadlock** ou de **signal perdu** si mal utilisÃ©

**âœ… C'est pour cette raison qu'Ã  l'Ã©tape suivante, tu as dÃ©cidÃ© d'abandonner `Condvar` au profit d'un simple `AtomicBool`.**

---

## ğŸ“Š Etape 4 â€” IntÃ©gration de `pcap` avec pause/reprise

### ğŸš€ Objectif
Passer du compteur simple Ã  une vraie capture de paquets rÃ©seau via la crate [`pcap`](https://docs.rs/pcap), tout en gardant la possibilitÃ© de mettre la capture **en pause** ou de l'arrÃªter grÃ¢ce Ã  des flags de contrÃ´le partagÃ©s avec le thread de capture.

---

### ğŸ”§ Code clÃ© : struct `CaptureHandle`

```rust
pub struct CaptureHandle {
    stop_flag: Arc<AtomicBool>,
    pause_flag: Arc<(Mutex<bool>, Condvar)>,
}
```

- `stop_flag` : permet d'interrompre la boucle de capture
- `pause_flag` : permet de suspendre temporairement le thread sans le tuer

---

### ğŸª¨ Logique de la boucle de capture

```rust
while !stop_flag.load(Ordering::Relaxed) {
    // pause si activÃ©e
    let (lock, cvar) = &*pause_flag;
    let mut paused = lock.lock().unwrap();
    while *paused {
        println!("[DEBUG] Pause active, en attente...");
        paused = cvar.wait(paused).unwrap();
        println!("[DEBUG] Reprise de la capture");
    }
    drop(paused);

    match cap.next_packet() {
        Ok(packet) => println!("[CAPTURE] paquet de {} octets", packet.data.len()),
        Err(e) => println!("[ERROR] Erreur de capture : {:?}", e),
    }

    let stats = cap.stats().unwrap();
    println!(
        "Received: {}, dropped: {}, if_dropped: {}",
        stats.received, stats.dropped, stats.if_dropped
    );
}
```

---

### ğŸ›€ Flowchart

```mermaid
flowchart TD
    UI["UI Vue.js"] --> start["start(interface)"]
    start --> Thread["thread::spawn"]
    Thread --> Loop["while !stop_flag"]
    Loop --> CheckPause{"pause_flag == true ?"}
    CheckPause -- Non --> Capture["cap.next_packet()"]
    Capture --> Stats["Affichage stats"]
    Stats --> Loop
    CheckPause -- Oui --> Wait["Condvar::wait"]
    Wait --> Resume["Reprise"] --> Loop
```

---

### âš ï¸ Limites identifiÃ©es

- `Condvar` peut bloquer le thread **alors que `pcap` supporte le mode non-bloquant**
- La gestion des erreurs devient plus complexe si des signaux sont manquÃ©s (ex : `notify_all()` ratÃ©)
- Ce modÃ¨le est plus adaptÃ© Ã  des processus **CPU-bloquants** que Ã  de la capture IO non-bloquante

---

### ğŸ“Š Conclusion

Cette Ã©tape permet de valider la chaÃ®ne :
- ContrÃ´le de thread avec pause/reprise sur une vraie capture rÃ©seau
- IntÃ©gration du `pcap::Capture` dans un thread
- Premiers tests de robustesse via `stop()` et `resume()`

âŒ **Mais les limites du modÃ¨le avec `Condvar` se font sentir.**

ğŸš§ Prochaine Ã©tape : remplacer `Condvar` par un simple `AtomicBool` pour un modÃ¨le plus adaptÃ© au non-blocking.

---
## ğŸš€ Etape 5 â€” Remplacement de `Condvar` par `AtomicBool`

### ğŸ”„ Objectif
Remplacer la pause/reprise basÃ©e sur `Condvar` par une solution plus simple et plus robuste avec **un `AtomicBool`**, mieux adaptÃ© Ã  la capture rÃ©seau en mode **non-bloquant** (`setnonblock()`).

---

### ğŸ”§ Architecture du `CaptureHandle`

```rust
pub struct CaptureHandle {
    stop_flag: Arc<AtomicBool>,
    pause_flag: Arc<AtomicBool>,
}
```

- `stop_flag` : indique au thread de s'arrÃªter
- `pause_flag` : contrÃ´le le gel temporaire de la capture

---

### âš–ï¸ Pourquoi abandonner `Condvar`

| `Condvar`                           | `AtomicBool`                          |
|------------------------------------|---------------------------------------|
| Bloque le thread                   | Polling actif mais contrÃ´lÃ©           |
| Difficile Ã  synchroniser avec `pcap` | Compatible avec `setnonblock()`        |
| Risques de signal perdu            | SimplicitÃ©, aucun verrou requis       |

---

### âœ… Comportement de la boucle de capture

```rust
if pause_flag.load(Ordering::Relaxed) {
    thread::sleep(Duration::from_millis(100));
    continue;
}
```

Cela permet au thread de rester rÃ©actif et non-bloquant tout en rÃ©duisant la charge CPU.

---

### ğŸ“Š Affichage intelligent des stats

Un cache `last_stats` permet d'Ã©viter d'afficher les statistiques en boucle :

```rust
if last_stats != Some(current) {
    println!("[STATS] Received: {}, dropped: {}, if_dropped: {}", ...);
    last_stats = Some(current);
}
```

---

### ğŸ›€ Flowchart

```mermaid
flowchart TD
    UI["UI Vue"] --> start["start(interface)"]
    start --> thread["thread::spawn"]
    thread --> loop["while !stop_flag"]
    loop --> checkPause{"pause_flag ?"}
    checkPause -- true --> wait["sleep(100ms)"] --> loop
    checkPause -- false --> capture["cap.next_packet()"] --> stats
    stats --> loop
    UI --> pause --> setPause["pause_flag = true"]
    UI --> resume --> clearPause["pause_flag = false"]
    UI --> stop --> setStop["stop_flag = true"]
```

---

### ğŸ” Ce qu'on gagne

- SimplicitÃ© de la logique de pause
- Plus de compatibilitÃ© avec les captures `pcap` non bloquantes
- Moins de complexitÃ© et de risque de bug

---

### ğŸ‰ Tu as maintenant :

- Un thread de capture **contrÃ´lable en `start`, `stop`, `pause`, `resume`**
- Une capture rÃ©seau **performante et robuste**
- Un code propre, testable et cross-plateforme

Prochaine Ã©tape : ğŸ“Š **SÃ©parer complÃ¨tement la capture des paquets et leur traitement **


## ğŸ§  Ã‰tape 6 â€” Thread sÃ©parÃ© pour traitement + stats

### ğŸ¯ Objectif

SÃ©parer complÃ¨tement la **capture** des paquets et leur **traitement** (parse, stats, etc.) dans deux threads indÃ©pendants.

---

### ğŸ“¦ Architecture

- Un `CaptureHandle` avec deux flags : `stop_flag` et `pause_flag`
- Un thread de **capture** qui lit les paquets via `pcap` et les envoie dans un canal
- Un thread de **traitement** qui lit depuis ce canal, dÃ©code les paquets, met Ã  jour les compteurs et affiche les stats
- Un enum `CaptureMessage` pour transmettre soit un paquet, soit les statistiques `pcap::Stat`

---

### ğŸ“„ Enum pour messages

```rust
enum CaptureMessage {
    Packet(PacketOwned),
    Stats(Stat),
}
```

---

### ğŸ“„ Thread de capture

```rust
thread::spawn(move || {
    // boucle de capture pcap
    match cap.next_packet() {
        Ok(packet) => {
            let owned = codec.decode(packet);
            tx.send(CaptureMessage::Packet(owned)).unwrap();
        },
        // ...
    }
    // stats pÃ©riodiques
    if let Ok(stats) = cap.stats() {
        tx.send(CaptureMessage::Stats(stats)).unwrap();
    }
});
```

---

### ğŸ“„ Thread de traitement

```rust
thread::spawn(move || {
    while let Ok(msg) = rx.recv() {
        match msg {
            CaptureMessage::Packet(pkt) => {
                println!("Packet len={} ts={}.{:06}", pkt.data.len(), pkt.header.ts.tv_sec, pkt.header.ts.tv_usec);
                // traitement, analyse...
            }
            CaptureMessage::Stats(stats) => {
                println!("[STATS] received={}, dropped={}, if_dropped={}...", stats.received, stats.dropped, stats.if_dropped);
            }
        }
    }
});
```

---

ğŸ“Š Flowchart â€“ Ã‰viter les paquets perdus en dÃ©lÃ©guant le traitement
```mermaid
flowchart TD
    start["start"] --> spawn_capture["thread::spawn capture"] & recv_thread["thread::spawn traitement"]
    subgraph capture
    spawn_capture --> loop_capture["while !stop_flag"]
    loop_capture --> checkPause{"pause_flag ?"}
    checkPause -- true --> wait_pause["sleep(100ms)"]
    wait_pause --> loop_capture
    checkPause -- false --> next_packet["cap.next_packet()"]
    next_packet --> send_packet["tx.send(Packet/Stat)"]
    end
    subgraph reciev
    send_packet -- fifo --> recv_loop
    recv_thread --> recv_loop
    recv_loop --> match_msg{"match msg"}
    match_msg -- Packet --> process_pkt["Decode + Analyse"]
    match_msg -- Stat --> update_stats["Afficher + Calculer delta"]
    end

```
---

### âœ… Ce que cette Ã©tape apporte

| Gain | DÃ©tail |
|------|--------|
| ğŸ“¦ SÃ©paration des responsabilitÃ©s | capture vs traitement |
| ğŸš€ Meilleure performance | capture non bloquÃ©e, traitement dÃ©couplÃ© |
| ğŸ§± Meilleure architecture | threads indÃ©pendants, plus testables |

---

### ğŸ”œ Prochaines Ã©tapes dâ€™optimisation

- ğŸ”„ Utiliser `crossbeam::bounded()` pour remplacer `mpsc::sync_channel`

---

## ğŸ§± Ã‰tape 7 â€” Transition de `mpsc` vers `crossbeam::channel`

### Pourquoi changer ?

- `std::sync::mpsc` est simple, mais limitÃ© :
  - pas de fonction `len()`
  - performances moindres en haute frÃ©quence
  - moins de flexibilitÃ© sur la stratÃ©gie de saturation

### Avantages concrets de `crossbeam::channel`

| FonctionnalitÃ©           | `mpsc`              | `crossbeam::channel`         |
|--------------------------|---------------------|-------------------------------|
| Taille bornÃ©e (`bounded`) | âœ… (avec `sync_channel`) | âœ…                           |
| `try_send()`             | âŒ                  | âœ…                            |
| `len()` pour monitoring  | âŒ                  | âœ…                            |
| Performances             | Moyennes            | Excellentes                  |
| SÃ©curitÃ© thread          | Bonne               | TrÃ¨s bonne                   |

### Code modifiÃ©

```rust
let (tx, rx) = crossbeam::channel::bounded::<CaptureMessage>(10_000);
```

Et dans le thread :

```rust
if let Err(err) = tx.try_send(CaptureMessage::Packet(owned)) {
    error!("[TX] Packet dropped (buffer plein) : {}", err);
}
```

---

### ğŸš¦ ScÃ©narios de saturation

- Le canal est plein car le thread de traitement est trop lent
- GrÃ¢ce Ã  `try_send()`, on peut **logguer ou ignorer** les paquets plutÃ´t que bloquer
- Avec `rx.len()` on peut **dÃ©tecter la saturation imminente** et **agir proactivement** (pause, discard, alertes...)

---

### ğŸ“„ Ã‰tape bonus : mise en place dâ€™un **backoff exponentiel**

Quand `pcap` nâ€™a pas de paquet Ã  lire, on dort un tout petit peu â€” mais progressivement plus longtemps, jusquâ€™Ã  10 ms max.

```rust
let mut backoff = 1; // Âµs
backoff = (backoff * 2).min(10_000);
```

Cela **rÃ©duit la charge CPU** tout en gardant une rÃ©activitÃ© raisonnable.

---

### ğŸ“„ Ã‰tape bonus : monitoring du canal

On mesure `rx.len()` dans le thread de traitement, et on dÃ©clenche un `warn!` si le canal est proche de la saturation :

```rust
if rx.len() > 9000 {
    warn!("[BACKPRESSURE] Canal presque plein !");
}
```

Cela permet de :
- Visualiser en prod si le thread de capture produit trop vite
- Ã‰ventuellement **adapter dynamiquement** la stratÃ©gie (discard, buffer, etc.)

---

### ğŸ“„ Thread de traitement

```rust
thread::spawn(move || {
    while let Ok(msg) = rx.recv() {
        match msg {
            CaptureMessage::Packet(pkt) => { /* traitement */ },
            CaptureMessage::Stats(stats) => { /* stats */ },
        }

        if rx.len() > 9000 {
            warn!("Canal presque saturÃ© !");
        }
    }
});
```

---

### âœ… Ce que cette Ã©tape apporte

| Gain                              | DÃ©tail                                   |
| --------------------------------- | ---------------------------------------- |
| ğŸ“¦ SÃ©paration des responsabilitÃ©s | capture vs traitement                    |
| ğŸš€ Meilleure performance          | capture non bloquÃ©e, traitement dÃ©couplÃ© |
| ğŸ§± Meilleure architecture         | threads indÃ©pendants, plus testables     |
| âš ï¸ DÃ©tection proactive            | backpressure visible dans les logs       |

---

### ğŸ“Š Flowchart â€“ Ã‰viter les paquets perdus en dÃ©lÃ©guant le traitement

```mermaid
flowchart TD
    subgraph Thread de capture
        A["cap.next_packet()"] --> B["try_send(Packet)"]
        B --> C["try_send(Stat)"]
        C --> D[Backoff exponentiel si vide]
    end

    subgraph Thread de traitement
        E["rx.recv()"] --> F{Message ?}
        F -- Packet --> G[Analyse + Affichage]
        F -- Stat --> H[Calcul stats + delta]
        G --> I["rx.len() > seuil ?"]
        H --> I
        I -- Oui --> J["warn!(Canal saturÃ©)"] --> E
        I -- Non --> E
    end

    style A fill:#66ccff
    style E fill:#66ffcc
```

---

### ğŸ”œ Prochaines Ã©tapes dâ€™optimisation

- â™»ï¸ RÃ©utiliser les buffers (`Vec<u8>` prÃ©-allouÃ©s)
- ğŸ§  ImplÃ©menter un pool dâ€™objets pour Ã©viter les reallocations frÃ©quentes

Tu es maintenant prÃªt Ã  **benchmark chaque taille de buffer**, et visualiser en direct lâ€™impact sur la perf ğŸ§ªğŸš€

